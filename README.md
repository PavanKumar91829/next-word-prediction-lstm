# LSTM Next Word Prediction

This project implements an LSTM-based neural network that predicts the next word in a text sequence.  
The model is trained on *Project Gutenbergâ€™s Sherlock Holmes* dataset to learn literary language patterns.

---

## ðŸ“‚ Project Overview

This project explores natural language processing (NLP) using a Long Short-Term Memory (LSTM) network.  
It processes text data, tokenizes it into sequences, and learns to predict the next probable word given context.

---

## ðŸ§° Technologies Used

- Python  
- TensorFlow / Keras  
- NumPy  
- Pandas  
- Matplotlib  
- NLTK  

---

## ðŸ“Š Dataset

Dataset source: [Project Gutenberg](https://www.gutenberg.org/)  
Book: *The Adventures of Sherlock Holmes* by Sir Arthur Conan Doyle.

---

## ðŸš€ How to Run

1. Clone this repository:
   ```bash
   git clone https://github.com/yourusername/next-word-prediction-lstm.git
   cd next-word-prediction-lstm
   ```

2. Open the Jupyter Notebook:
   ```bash
   jupyter notebook next-word-prediction-lstm.ipynb
   ```

3. Run all cells to preprocess data, train the model, and test predictions.

---

## ðŸ“š Future Improvements

- Experiment with GRU or Transformer architectures  
- Use larger and multi-author datasets  
- Build an interactive web interface  

---

## ðŸ§¾ License

This project is licensed under the MIT License.  
Dataset Â© Project Gutenberg â€“ Public Domain.
---
